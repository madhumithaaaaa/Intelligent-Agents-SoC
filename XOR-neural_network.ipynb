{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzbimHtX+P/7ZgzOvbiQRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhumithaaaaa/Intelligent-Agents-SoC/blob/master/XOR-neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY0am6mjC-kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Network(object):\n",
        "  \n",
        "    def __init__(self, no_of_inputs, epochs=10000, learning_rate=0.1):\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "          \n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1-x)\n",
        "\n",
        "\n",
        "    def train(self, X, y):\n",
        "        #Initializing size of layers\n",
        "        inputNeurons = 2\n",
        "        hiddenNeurons = 2\n",
        "        outputNeurons = 1\n",
        "        \n",
        "        #Random initialisation of weights and biases of hidden and output layer\n",
        "        hidden_weights = np.random.uniform(size=(inputNeurons, hiddenNeurons))\n",
        "        hidden_bias = np.random.uniform(size=(1, hiddenNeurons))\n",
        "\n",
        "        output_weights = np.random.uniform(size=(hiddenNeurons, outputNeurons))\n",
        "        output_bias = np.random.uniform(size=(1, outputNeurons))\n",
        " \n",
        "        \n",
        "        #Training model\n",
        "        for i in range(self.epochs):\n",
        "            #Forward pass\n",
        "            hidden_layer_activation = np.dot(X_train, hidden_weights) + hidden_bias\n",
        "            hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
        "\n",
        "            output_layer_activation = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "            predicted_output = self.sigmoid(output_layer_activation)\n",
        "    \n",
        "            #Backpropagation\n",
        "            error = y_train - predicted_output\n",
        "            d_predicted_output = error * self.sigmoid_derivative(predicted_output)\n",
        "    \n",
        "            error_hidden_layer = np.dot(d_predicted_output, output_weights.T)\n",
        "            d_hidden_layer = error_hidden_layer * self.sigmoid_derivative(hidden_layer_output)\n",
        "    \n",
        "            #Updating weights and biases\n",
        "            output_weights += self.learning_rate * np.dot(hidden_layer_output.T, d_predicted_output)\n",
        "            output_bias += self.learning_rate * np.sum(d_predicted_output, axis=0, keepdims=True)\n",
        "\n",
        "            hidden_weights += self.learning_rate * np.dot(X_train.T, d_hidden_layer)\n",
        "            hidden_bias += self.learning_rate * np.sum(d_hidden_layer, axis=0, keepdims=True)\n",
        "        \n",
        "        return hidden_weights, hidden_bias, output_weights, output_bias\n",
        "            \n",
        "    def predict(self, inputs):\n",
        "        hidden_weights, hidden_bias, output_weights, output_bias = self.train(X_train, y_train)\n",
        "        \n",
        "        hidden_layer_activation = np.dot(inputs, hidden_weights) + hidden_bias\n",
        "        hidden_layer_output = self.sigmoid(hidden_layer_activation)\n",
        "\n",
        "        output_layer_activation = np.dot(hidden_layer_output, output_weights) + output_bias\n",
        "        predicted_output = self.sigmoid(output_layer_activation)\n",
        "        if predicted_output >= 0.5:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA2L6buwDEx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "49bbeaf4-aff9-45f0-f163-35187ee131b4"
      },
      "source": [
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "network = Network(2)\n",
        "\n",
        "inputs = []\n",
        "for i in range(2):\n",
        "    inputs.append(int(input('Input {}: '.format(i+1))))\n",
        "\n",
        "X_test = np.array(inputs)\n",
        "network.predict(X_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input 1: 1\n",
            "Input 2: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT21LfXzDL73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}